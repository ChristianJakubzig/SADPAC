# ğŸ¤– RAG Chatbot mit Ollama

Ein intelligenter Chatbot, der mittels **Retrieval Augmented Generation (RAG)** Fragen zu hochgeladenen Dokumenten beantwortet. Nutzt Ollama fÃ¼r LLM und Embeddings, ChromaDB als Vektordatenbank und Streamlit als UI.

## ğŸ“‹ Inhaltsverzeichnis

- [Features](#-features)
- [Architektur](#-architektur)
- [Voraussetzungen](#-voraussetzungen)
- [Installation](#-installation)
- [Verwendung](#-verwendung)
  - [Entwicklung](#entwicklung-lokal)
  - [Production](#production-docker)
- [Dokumenten-Management](#-dokumenten-management)
- [Konfiguration](#-konfiguration)
- [Projekt-Struktur](#-projekt-struktur)
- [Troubleshooting](#-troubleshooting)

---

## âœ¨ Features

- ğŸ“š **Multi-Format Support**: PDF, TXT, DOCX
- ğŸ” **Semantische Suche**: Findet relevante Textabschnitte in Dokumenten
- ğŸ’¬ **Streaming Chat**: LLM-Antworten erscheinen in Echtzeit
- ğŸ“Š **Zwei Collections**: Separate Verwaltung von Dokumenten und Metadaten
- ğŸ¯ **Quellen-Nachweis**: Zeigt verwendete Textabschnitte mit Relevanz-Scores
- ğŸ³ **Docker-Ready**: VollstÃ¤ndig containerisiert fÃ¼r einfaches Deployment
- âš¡ **Batch-Processing**: Verarbeitet groÃŸe Dokumente in Batches

---

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚  â† Browser (Port 8501)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     RAG Pipeline             â”‚
    â”‚  (Retrieval + Generation)    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ChromaDB   â”‚    â”‚ Ollama Serverâ”‚
    â”‚  (Lokal)    â”‚    â”‚ (TH Wildau)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Komponenten:

- **Streamlit**: Web-UI fÃ¼r Chat und Dokumenten-Upload
- **ChromaDB**: Vektordatenbank fÃ¼r Embeddings (lÃ¤uft lokal in Docker)
- **Ollama**: LLM (llama3.2) und Embeddings (granite-embedding:278m) auf TH Wildau Server
- **LangChain**: Orchestrierung der RAG-Pipeline

---

## ğŸ“¦ Voraussetzungen

- **Docker** & **Docker Compose**
- **Python 3.12+** (fÃ¼r lokale Entwicklung)
- **uv** (Python Package Manager) - [Installation](https://docs.astral.sh/uv/)
- **Make** (optional, aber empfohlen)
- Zugang zum **TH Wildau Ollama-Server** (oder eigener Ollama-Server)

### System-Anforderungen:

- **Speicherplatz**: ~5 GB fÃ¼r Docker Images + Daten
- **RAM**: Mindestens 4 GB
- **Netzwerk**: Zugang zu TH Wildau Proxy (bei Verwendung des Uni-Servers)

---

## ğŸš€ Installation

### 1. Repository klonen

```bash
git clone <repository-url>
cd python
```

### 2. Dependencies installieren (fÃ¼r lokale Entwicklung)

```bash
make install
# oder
uv sync
```

---

## ğŸ’» Verwendung

### Entwicklung (Lokal)

**Ideal fÃ¼r Code-Ã„nderungen und schnelles Testing**

```bash
# 1. Starte ChromaDB in Docker
make dev

# 2. Starte Streamlit-App lokal
make run

# App lÃ¤uft auf: http://localhost:8501
```

**Vorteile:**
- âš¡ Schnelle Iterationen (kein Container-Rebuild)
- ğŸ› Einfaches Debugging
- ğŸ”„ Code-Ã„nderungen sofort sichtbar

**Stoppen:**
```bash
# Streamlit: Strg+C
# ChromaDB:
make docker-down
```

---

### Production (Docker)

**Deployment-Ready, alles in Containern**

```bash
# 1. Baue Docker Images
make docker-build

# 2. Starte alle Services
make prod

# App lÃ¤uft auf: http://localhost:8501
```

**Services:**
- ğŸ“Š ChromaDB: `http://localhost:8000`
- ğŸ¤– RAG App: `http://localhost:8501`

**Management:**
```bash
# Status prÃ¼fen
make docker-ps

# Logs ansehen
make docker-logs              # Alle Services
make docker-logs-app          # Nur RAG-App
make docker-logs-chroma       # Nur ChromaDB

# Neustart
make docker-restart

# Stoppen
make docker-down
```

---

## ğŸ“š Dokumenten-Management

### Via Web-UI

1. Ã–ffne `http://localhost:8501`
2. Gehe zu **ğŸ“š Dokumente**
3. WÃ¤hle Collection (documents/metadata)
4. Lade Dateien hoch

### Via Script (Bulk-Loading)

**Empfohlen fÃ¼r viele Dokumente**

```bash
# Dokumente laden
make load-docs

# Metadaten laden
make load-metadata

# Beide laden
make load-all

# Mit Clear (DB vorher leeren)
make load-docs-clear
```

**Erweiterte Optionen:**
```bash
# Custom Ordner
python src/scripts/load_documents.py \
  --folder /pfad/zu/dokumenten \
  --collection documents-collection \
  --batch-size 5

# Kleinere Batches bei Timeouts
python src/scripts/load_documents.py \
  --folder data/documents \
  --batch-size 3 \
  --clear
```

### UnterstÃ¼tzte Formate

- âœ… PDF (`.pdf`)
- âœ… Text (`.txt`)
- âœ… Word (`.docx`)

---

## âš™ï¸ Konfiguration

### TH Wildau Proxy

Bei Verwendung im TH Wildau Netzwerk ist der Proxy bereits in `docker-compose.yml` konfiguriert:

```yaml
environment:
  - http_proxy=http://proxy.th-wildau.de:8080
  - https_proxy=http://proxy.th-wildau.de:8080
```

**FÃ¼r externes Deployment:** Entferne Proxy-Einstellungen aus `docker-compose.yml`.

---

## ğŸ“ Projekt-Struktur

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chromadb/          # ChromaDB Daten (persistent)
â”‚   â”œâ”€â”€ documents/         # Dokumente fÃ¼r documents-collection
â”‚   â””â”€â”€ metadata/          # Dokumente fÃ¼r metadata-collection
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ chroma_client.py        # ChromaDB Verbindung
â”‚   â”‚   â”œâ”€â”€ config.py               # Konfiguration
â”‚   â”‚   â”œâ”€â”€ document_processor.py   # PDF/TXT/DOCX Verarbeitung
â”‚   â”‚   â””â”€â”€ rag_pipeline.py         # RAG Logic (Retrieval + Generation)
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ“š_Dokumente.py      # Dokumenten-Upload & Verwaltung
â”‚   â”‚   â””â”€â”€ 2_ğŸ’¬_Chat.py           # Chat-Interface
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ load_documents.py       # Bulk-Loading Script
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ test_chroma_client.py   # Tests
â”‚   â””â”€â”€ Home.py                     # Streamlit Hauptseite
â”œâ”€â”€ docker-compose.yml     # Docker Services Definition
â”œâ”€â”€ Dockerfile            # RAG-App Container
â”œâ”€â”€ Makefile             # Convenience Commands
â””â”€â”€ pyproject.toml       # Python Dependencies
```

---

## ğŸ§ª Tests

```bash
# Teste ChromaDB Verbindung
make test

---

## ğŸ§¹ Maintenance

### Cleanup

```bash
# TemporÃ¤re Dateien lÃ¶schen
make clean

# Inkl. ChromaDB Daten (Vorsicht!)
make clean-all
```

### Docker AufrÃ¤umen

```bash
# Speicherplatz freigeben
sudo docker system prune -a --volumes
```

---

## ğŸ› Troubleshooting

### ChromaDB nicht erreichbar

```bash
# Status prÃ¼fen
make docker-ps

# Logs ansehen
make docker-logs-chroma

# Neustart
make docker-restart
```

### Timeout beim Dokumenten-Upload

**Problem:** Ollama-Server antwortet nicht rechtzeitig

**LÃ¶sung:** Reduziere Batch-Size
```bash
# In UI: Upload-Einstellungen â†’ Batch-Size auf 3-5 setzen
# Via Script:
python src/scripts/load_documents.py --batch-size 3
```

---

## ğŸ“š Verwendete Technologien

- **[Streamlit](https://streamlit.io/)** - Web UI Framework
- **[LangChain](https://www.langchain.com/)** - LLM Application Framework
- **[ChromaDB](https://www.trychroma.com/)** - Vector Database
- **[Ollama](https://ollama.ai/)** - LLM Runtime
- **[uv](https://docs.astral.sh/uv/)** - Fast Python Package Manager
- **[Docker](https://www.docker.com/)** - Containerization

---

## ğŸ“ Makefile Commands Ãœbersicht

```bash
make help              # Zeigt alle verfÃ¼gbaren Commands

# Development
make dev               # Startet ChromaDB fÃ¼r lokale Entwicklung
make run               # Startet App lokal

# Production
make docker-build      # Baut Docker Images
make prod              # Startet komplette App in Docker
make docker-down       # Stoppt alle Container

# Daten
make load-docs         # LÃ¤dt Dokumente
make load-metadata     # LÃ¤dt Metadaten
make load-all          # LÃ¤dt alles

# Monitoring
make docker-ps         # Container Status
make docker-logs       # Alle Logs
make docker-logs-app   # Nur App-Logs

# Maintenance
make clean             # Cleanup
make test              # Tests ausfÃ¼hren
```

---

**Viel Erfolg mit deinem RAG Chatbot! ğŸš€**